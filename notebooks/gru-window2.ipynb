{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path[0] = ('/home/labs/waic/omrik/DNN-Challenge')\n",
    "from fastai.vision import *\n",
    "import pre\n",
    "import resample\n",
    "from metrics import Pearson\n",
    "from fastai.utils.mod_display import *\n",
    "from utils import ProgressBarCtx\n",
    "\n",
    "root = Path('/home/labs/waic/omrik/DNN-Challenge/data').resolve()\n",
    "train = root / 'train'\n",
    "val = root / 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_time(series):\n",
    "    # 1440 minutes in a day\n",
    "    normalized = (series.hour * 60 + series.minute) / 1440\n",
    "    return normalized\n",
    "\n",
    "def get_data(data_dir):\n",
    "    cgm, meals = pre.get_dfs(data_dir)\n",
    "    meals = resample.resample_meals(cgm, meals, 15)\n",
    "    meals = pd.concat((meals, cgm), axis=1)\n",
    "    meals['time'] = normalize_time(meals.index.get_level_values('Date'))\n",
    "    cgm, y = pre.build_cgm(cgm, drop=False)\n",
    "    return cgm, meals, y\n",
    "\n",
    "class ContData(Dataset):\n",
    "    def __init__(self, cgm, meals, y):\n",
    "        self.cgm = cgm.loc[y.index].dropna(how='any', axis=0)\n",
    "        self.meals = meals\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.cgm)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        index = self.meals.index.get_loc(self.cgm.index[i])\n",
    "        values = self.meals[index-48:index+1].values\n",
    "        index = self.y.index.get_loc(self.cgm.index[i])\n",
    "        target = self.y.iloc[index-48:index+1]\n",
    "        x, y = torch.tensor(values, dtype=torch.float), torch.tensor(target.values, dtype=torch.float)\n",
    "        return x, y\n",
    "    \n",
    "def loss(outputs, targets, start_idx=0):\n",
    "    targets = targets.transpose(0, 1)\n",
    "    return F.mse_loss(outputs[start_idx:], targets[start_idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_data(train)\n",
    "val_data = get_data(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ContData(*train_data)\n",
    "val_ds = ContData(*val_data)\n",
    "data = DataBunch.create(train_ds, val_ds, bs=512)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowPearson(Pearson):\n",
    "    def __init__(self, gt):\n",
    "        super().__init__(gt)\n",
    "        \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        super().on_batch_end(last_output[-1], last_target, **kwargs)\n",
    "        \n",
    "p = WindowPearson(val_ds.y.loc[val_ds.cgm.index].dropna(how='any', axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 49\n",
    "\n",
    "\n",
    "class Seq2Lin(Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "        self.decoder = nn.Linear(hidden_size, 8)\n",
    "\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = input.transpose(0, 1)\n",
    "        encoder_outputs, _ = self.encoder(input)\n",
    "        out = self.decoder(encoder_outputs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dropout = 0.1\n",
    "start_idx = -11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNoise(Callback):\n",
    "    \n",
    "    def __init__(self, std):\n",
    "        self.std = std\n",
    "        \n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        if not train:\n",
    "            return\n",
    "        \n",
    "        size = last_input.shape[:2]\n",
    "        noise = torch.normal(0, self.std, size).to(last_input.device)\n",
    "        last_input[..., -2] += noise\n",
    "        return {'last_input': last_input}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Lin(38, 128, num_layers=4, dropout=dropout)\n",
    "learner = Learner(data, model, loss_func=partial(loss, start_idx=start_idx), metrics=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBarCtx(learner, False) as l:\n",
    "    l.lr_find()\n",
    "    l.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBarCtx(learner, False) as l:\n",
    "    l.fit_one_cycle(10, 5e-4)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
